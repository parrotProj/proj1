{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parrot_Project1 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dz42sDRoajx",
        "colab_type": "text"
      },
      "source": [
        "https://colab.research.google.com/github/parrotProj/proj1/blob/master/modifed_res.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijBz5lHge0aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY3ayNNMe8rZ",
        "colab_type": "code",
        "outputId": "9c2d81c3-a188-4631-8b4d-f373c57a30ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone \"https://github.com/parrotProj/proj1\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'proj1' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phfq2bMZmT64",
        "colab_type": "code",
        "outputId": "444a41fa-5b11-4768-fee6-1c6e701c4c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mproj1\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ocxLcVomaqK",
        "colab_type": "code",
        "outputId": "6bb6a3e8-fba6-48d7-e8ee-3cfb87995439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd proj1/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/proj1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMlg0QQHGCjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Request\n",
        "X_train, Y_train = Request.get_data.train()\n",
        "X_test,X_id=Request.get_data.test()\n",
        "np.random.seed(123577)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L10orhzaVWfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    if X_train[i].shape[0] != 150:\n",
        "        X_train[i] = resize(X_train[i],(150,150,3))\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    if X_test[i].shape[0] != 150:\n",
        "        X_test[i] = resize(X_test[i],(150,150,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sRTgtp6m7Qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomCrop(img, width, height):\n",
        "    assert img.shape[0] >= height\n",
        "    assert img.shape[1] >= width\n",
        "      \n",
        "    x = random.randint(0, img.shape[1] - width)\n",
        "    y = random.randint(0, img.shape[0] - height)\n",
        "    img = img[y:y+height, x:x+width]\n",
        "\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMJhQsrtm8e-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "XX_train=[]\n",
        "for i in range(len(X_train)):\n",
        "    XX_train.append(randomCrop(X_train[i],150,150))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo_gH1LCnF2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "922b1c58-6178-4a5e-815b-2cb34d7903cf"
      },
      "source": [
        "XX_train = np.array(XX_train)\n",
        "XX_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14034, 150, 150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InQh9Kuom8Xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XX_test=[]\n",
        "for i in range(len(X_test)):\n",
        "    XX_test.append(randomCrop(X_test[i],150,150))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk16YhpKnHsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff1a6e4b-2d43-48e2-8c37-2f8ceb233de1"
      },
      "source": [
        "XX_test=np.array(XX_test)\n",
        "XX_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 150, 150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW37MuWkW4q1",
        "colab_type": "code",
        "outputId": "0f4645b5-0dd0-476d-aca1-a1612196cb4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y_train = to_categorical(Y_train)\n",
        "print(X_train.shape,Y_train.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(14034,) (14034, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Hk8moJ-XEz",
        "colab_type": "code",
        "outputId": "26b8a971-2589-472f-e33a-ce27afc0b353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization, Convolution2D, MaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Activation, Dropout\n",
        "from keras.layers import Add, ZeroPadding2D, Flatten\n",
        "\n",
        "def input_block(x):\n",
        "    \n",
        "    x = ZeroPadding2D(padding=(2,2))(x)\n",
        "    x = Convolution2D(64, (3,3), strides = (1,1), kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = ZeroPadding2D(padding=(1,1))(x)\n",
        "    x = Convolution2D(64, (3,3), strides = (1,1), kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def residual_block(x,channels,d_increase=False):\n",
        "    shortcut = x\n",
        "  \n",
        "\n",
        "    x = Convolution2D(int(channels/4.0), (1,1), padding = \"valid\", kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(int(channels/4.0), (3,3), padding = \"same\", kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(channels, (1,1), padding = \"valid\", kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    shortcut = Convolution2D(channels, (1,1), strides=(1,1), padding = \"valid\", kernel_initializer = 'he_normal')(shortcut)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Add()([x,shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_group(x, channels, num_blocks,d_increase=False):\n",
        "    for i in range(num_blocks):\n",
        "        if i==0 :\n",
        "            x = residual_block(x,channels,d_increase)\n",
        "        else:\n",
        "            x = residual_block(x,channels,)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxlCVY-j-YXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def result(x, channels=64):\n",
        "    input_data=x            #150 * 150 *3\n",
        "    x = input_block(x)\n",
        "    x = MaxPooling2D((3,3),2)(x)\n",
        "\n",
        "    x = block_group(x, 128, 5, d_increase=False)\n",
        "    x = MaxPooling2D((2,2),2)(x)\n",
        "\n",
        "    x = block_group(x, 256, 7, d_increase=True)\n",
        "    x = MaxPooling2D((2,2),2)(x)\n",
        "\n",
        "    x = block_group(x, 512, 4, d_increase=True)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    output_data = Dense(6,activation='softmax')(x)\n",
        "    \n",
        "    model = Model(input_data,output_data)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0aMljwy-aq6",
        "colab_type": "code",
        "outputId": "52e91952-ec18-4e38-c065-4fd5001de7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "inputs = Input(shape=(150,150,3),dtype='float32')\n",
        "model = result(inputs)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "302iBXxo-n7w",
        "colab_type": "code",
        "outputId": "a79f1bac-592f-4673-db7c-cefa0bdfe331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#hist=model.fit(x=XX_train,y=Y_train,validation_split=0.2,batch_size=56,epochs=100)\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 154, 154, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 152, 152, 64) 1792        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 152, 152, 64) 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 152, 152, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 154, 154, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 152, 152, 64) 36928       zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 152, 152, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 152, 152, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 75, 75, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 75, 75, 32)   2080        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 75, 75, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 75, 75, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 75, 75, 32)   9248        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 75, 75, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 75, 75, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 75, 75, 128)  4224        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 75, 75, 128)  8320        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 75, 75, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 75, 75, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 75, 75, 128)  0           batch_normalization_5[0][0]      \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 75, 75, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 75, 75, 32)   4128        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 75, 75, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 75, 75, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 75, 75, 32)   9248        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 75, 75, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 75, 75, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 75, 75, 128)  4224        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 75, 75, 128)  16512       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 75, 75, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 75, 75, 128)  512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 75, 75, 128)  0           batch_normalization_9[0][0]      \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 75, 75, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 75, 75, 32)   4128        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 75, 75, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 75, 75, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 75, 75, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 75, 75, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 75, 75, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 75, 75, 128)  4224        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 75, 75, 128)  16512       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 75, 75, 128)  512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 75, 75, 128)  512         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 75, 75, 128)  0           batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 75, 75, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 75, 75, 32)   4128        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 75, 75, 32)   128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 75, 75, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 75, 75, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 75, 75, 32)   128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 75, 75, 32)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 75, 75, 128)  4224        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 75, 75, 128)  16512       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 75, 75, 128)  512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 75, 75, 128)  512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 75, 75, 128)  0           batch_normalization_17[0][0]     \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 75, 75, 128)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 75, 75, 32)   4128        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 75, 75, 32)   128         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 75, 75, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 75, 75, 32)   9248        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 75, 75, 32)   128         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 75, 75, 32)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 75, 75, 128)  4224        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 75, 75, 128)  16512       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 75, 75, 128)  512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 75, 75, 128)  512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 75, 75, 128)  0           batch_normalization_21[0][0]     \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 75, 75, 128)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 37, 37, 128)  0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 37, 37, 64)   8256        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 37, 37, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 37, 37, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 37, 37, 64)   36928       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 37, 37, 64)   256         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 37, 37, 64)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 37, 37, 256)  16640       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 37, 37, 256)  33024       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 37, 37, 256)  1024        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 37, 37, 256)  1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 37, 37, 256)  0           batch_normalization_25[0][0]     \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 37, 37, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 37, 37, 64)   16448       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 37, 37, 64)   256         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 37, 37, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 37, 37, 64)   36928       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 37, 37, 64)   256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 37, 37, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 37, 37, 256)  16640       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 37, 37, 256)  65792       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 37, 37, 256)  1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 37, 37, 256)  1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 37, 37, 256)  0           batch_normalization_29[0][0]     \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 37, 37, 256)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 37, 37, 64)   16448       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 37, 37, 64)   256         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 37, 37, 64)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 37, 37, 64)   36928       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 37, 37, 64)   256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 37, 37, 64)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 37, 37, 256)  16640       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 37, 37, 256)  65792       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 37, 37, 256)  1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 37, 37, 256)  1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 37, 37, 256)  0           batch_normalization_33[0][0]     \n",
            "                                                                 batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 37, 37, 256)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 37, 37, 64)   16448       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 37, 37, 64)   256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 37, 37, 64)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 37, 37, 64)   36928       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 37, 37, 64)   256         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 37, 37, 64)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 37, 37, 256)  16640       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 37, 37, 256)  65792       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 37, 37, 256)  1024        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 37, 37, 256)  1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 37, 37, 256)  0           batch_normalization_37[0][0]     \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 37, 37, 256)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 37, 37, 64)   16448       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 37, 37, 64)   256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 37, 37, 64)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 37, 37, 64)   36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 37, 37, 64)   256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 37, 37, 64)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 37, 37, 256)  16640       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 37, 37, 256)  65792       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 37, 37, 256)  1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 37, 37, 256)  1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 37, 37, 256)  0           batch_normalization_41[0][0]     \n",
            "                                                                 batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 37, 37, 256)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 37, 37, 64)   16448       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 37, 37, 64)   256         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 37, 37, 64)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 37, 37, 64)   36928       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 37, 37, 64)   256         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 37, 37, 64)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 37, 37, 256)  16640       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 37, 37, 256)  65792       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 37, 37, 256)  1024        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 37, 37, 256)  1024        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 37, 37, 256)  0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 37, 37, 256)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 37, 37, 64)   16448       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 37, 37, 64)   256         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 37, 37, 64)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 37, 37, 64)   36928       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 37, 37, 64)   256         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 37, 37, 64)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 37, 37, 256)  16640       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 37, 37, 256)  65792       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 37, 37, 256)  1024        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 37, 37, 256)  1024        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 37, 37, 256)  0           batch_normalization_49[0][0]     \n",
            "                                                                 batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 37, 37, 256)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 18, 18, 256)  0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 18, 18, 128)  32896       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 18, 18, 128)  512         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 18, 18, 128)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 18, 18, 128)  147584      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 18, 18, 128)  512         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 18, 18, 128)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 18, 18, 512)  66048       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 18, 18, 512)  131584      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 18, 18, 512)  2048        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 18, 18, 512)  2048        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 18, 18, 512)  0           batch_normalization_53[0][0]     \n",
            "                                                                 batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 18, 18, 512)  0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 18, 18, 128)  65664       activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 18, 18, 128)  512         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 18, 18, 128)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 18, 18, 128)  147584      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 18, 18, 128)  512         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 18, 18, 128)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 18, 18, 512)  66048       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 18, 18, 512)  262656      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 18, 18, 512)  2048        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 18, 18, 512)  2048        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 18, 18, 512)  0           batch_normalization_57[0][0]     \n",
            "                                                                 batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 18, 18, 512)  0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 18, 18, 128)  65664       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 18, 18, 128)  512         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 18, 18, 128)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 18, 18, 128)  147584      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 18, 18, 128)  512         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 18, 18, 128)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 18, 18, 512)  66048       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 18, 18, 512)  262656      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 18, 18, 512)  2048        conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 18, 18, 512)  2048        conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 18, 18, 512)  0           batch_normalization_61[0][0]     \n",
            "                                                                 batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 18, 18, 512)  0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 18, 18, 128)  65664       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 18, 18, 128)  512         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 18, 18, 128)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 18, 18, 128)  147584      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 18, 18, 128)  512         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 18, 18, 128)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 18, 18, 512)  66048       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 18, 18, 512)  262656      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 18, 18, 512)  2048        conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 18, 18, 512)  2048        conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 18, 18, 512)  0           batch_normalization_65[0][0]     \n",
            "                                                                 batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 18, 18, 512)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 512)          0           activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 6)            3078        global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 3,161,094\n",
            "Trainable params: 3,138,438\n",
            "Non-trainable params: 22,656\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn74VCAjTfg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(shear_range=0.05, width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   horizontal_flip=True, zoom_range=0.2)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_Val, Y_train, Y_Val = train_test_split(XX_train,Y_train, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDQwUxKHrW33",
        "colab_type": "code",
        "outputId": "e78288c8-fa41-4a11-f8da-cc0f2db91f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "train_generator = train_datagen.flow(X_train,Y_train,batch_size=64)\n",
        "hist=model.fit_generator(train_generator,steps_per_epoch=128,validation_data=(X_Val,Y_Val),\n",
        "               validation_steps=32,epochs=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/30\n",
            "128/128 [==============================] - 109s 849ms/step - loss: 1.2129 - acc: 0.5170 - val_loss: 5.1756 - val_acc: 0.2044\n",
            "Epoch 2/30\n",
            "128/128 [==============================] - 79s 616ms/step - loss: 0.8873 - acc: 0.6467 - val_loss: 4.3050 - val_acc: 0.4152\n",
            "Epoch 3/30\n",
            " 29/128 [=====>........................] - ETA: 57s - loss: 0.7977 - acc: 0.6994"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvrltWrVDBH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,loss_ax=plt.subplots(figsize=(12,5))\n",
        "acc_ax=loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'],'indianred',marker='*',label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'],'lightcoral',marker='*',label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['acc'],'forestgreen',marker='*',label='train accuary')\n",
        "acc_ax.plot(hist.history['val_acc'],'olivedrab',marker='*',label='val accuary')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS48CGug9UHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=model.predict(X_Val,batch_size=32)\n",
        "result = np.argmax(pred,axis=1).reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLYnZbIBDqXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.predict(XX_test,batch_size=32)\n",
        "result = np.argmax(result,axis=1).reshape(-1,1)\n",
        "\n",
        "X_id_pd = pd.DataFrame(X_id)\n",
        "X_id_pd = X_id_pd[0].apply(lambda x:x.split('.')[0])\n",
        "output = pd.DataFrame(X_id_pd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWdfV-g1D2qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output['pred_label'] = result\n",
        "output.columns = ['id','pred_label']\n",
        "output.set_index('id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAXvGPhND8Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.to_csv('prediction.csv')\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"prediction.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpmR3ghFmiYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Convolution : 컨볼루션 레이어, 필터로 특징을 뽑아주는 레이어.\n",
        "\n",
        "## Convolution2D(컨볼루션 필터의 수, 컨볼루션 커널의 (행,열), padding, input_shape)\n",
        "##               필터는 가중치를 의미하며, 하나의 필터가 입력 이미지를 순회하면서 적용된 결과값을 모으면 출력이미지가 생성됨\n",
        "##               순회할 때 적용되는 가중치는 모두 동일함 (파라미터 공유) => 학습해야할 가중치를 줄임, 이미지 인식에 적합\n",
        "\n",
        "## padding : 경계 처리 방법을 정의. 'valid' : 유효한 영역만 출력. 출력 이미지 사이즈는 입력 사이즈보다 작음\n",
        "##                                 'same' : 출력 이미지 사이즈가 입력 이미지 사이즈와 동일.\n",
        "\n",
        "## input_shape : 샘플 수를 제외한 입력 형태를 정의. 첫 레이어에서만 정의하면 된다.\n",
        "##               (행,열,채널 수)로 정의함. 흑백인 경우 채널 = 1,컬러인 경우 채널 = 3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## MaxPooling : 맥스풀링 레이어. 사소한 변화를 무시해준다. (지엽적인 부분이 영향을 미치지 않도록 한다.)\n",
        "##              컨볼루션 레이어의 출력 이미지에서 주요값만 뽑아 크기가 작은 출력 이미지를 만든다\n",
        "## MaxPooling2D(pool_size)\n",
        "## pool_size : 수직, 수평 수평 축소 비율을 지정 ((2,2)면 출력 영상 크기는 입력 영상 크기의 반으로 줄어든다)\n",
        "\n",
        "\n",
        "## 컨볼루션 레이어나 맥스풀링 레이어를 반복적으로 수행하면 주요 특징만 추출된다\n",
        "## 추출된 주요 특징은 전결합층에 전달되어 학습된다.\n",
        "## 컨볼루션과 맥스풀링은 2차원 데이터를 다루지만 전결합층에 전달하기 위해서는 1차원 자료로 바꿔줘야한다.\n",
        "## Flatten : 1차원 자료로 바꿔주는 레이어"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL-WEwauVB6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output['count']=1\n",
        "output.groupby('pred_label').sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCR0x8gwK7SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output['count']=1\n",
        "output.groupby('pred_label').sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZCIrvkoTVJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}